{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Computer Assignment 1 - AI Search </center>\n",
    "##  In this project, we want to work on some uninformed algorithms like BFS and IDS and also some informed algorithms like $A^*$.<br><br> **Uninformed Search** algorithms are the strategies that use only the information available in the problem definition.<br><br>**Informed Search** algorithms use some hints about the desirability of different states too.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **Problem Description:** We have a map with n rows and m columns, with one agent at the start point(0, 0) <br> There are some foods and medicines on the map too. Also there are some blocked cells that the agents can't go to. If an agent goes to a cell with a medicine on it, another agent will appear in the cell (n-1, 0). <br>When agents go to a cell, they should eat whatever in that cell is. (either food or medicine)<br>What the problem asks us, is to find an optimal way to eat all the foods and also take all the agents to the endpoint(n-1, m-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### In this project we are going to:\n",
    "- Defining the terms of Agent and State in AI search strategies\n",
    "- Implementing BFS\n",
    "- Implementing IDS\n",
    "- Defining huristic function\n",
    "- Defining an evaluation function\n",
    "- Implementing $A^*$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "import math\n",
    "import heapq # min heap used in A-star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Reading the inputs from the file\n",
    "#### You only need to give the name of your test file that is in the Tests folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input(file_name):\n",
    "    lines = []\n",
    "    with open(file_name) as test:\n",
    "        while (line := test.readline().rstrip()):\n",
    "            lines.append(line)\n",
    "            \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test2.in\n"
     ]
    }
   ],
   "source": [
    "filename = input()\n",
    "path = 'Tests/' + filename\n",
    "test = read_input(path)\n",
    "\n",
    "# n: No of rows, m: No of cols\n",
    "n, m = test[0].split(' ')\n",
    "n, m = int(n), int(m)\n",
    "c, k = test[1].split(' ')\n",
    "c, k = int(c), int(k)\n",
    "game_map = {}\n",
    "medicines = []\n",
    "foods = []\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(m):\n",
    "        game_map[(i,j)] = 'e'\n",
    "        \n",
    "for i in range(c):\n",
    "    x, y = test[2+i].split(' ')\n",
    "    x, y = int(x), int(y)\n",
    "    game_map[(x,y)] = 'food'\n",
    "    foods.append((x,y))\n",
    "    \n",
    "for i in range(k):\n",
    "    x, y = test[2+c+i].split(' ')\n",
    "    x, y = int(x), int(y)\n",
    "    game_map[(x,y)] = 'medicine'\n",
    "    medicines.append((x, y))\n",
    "    \n",
    "# d: No of block nodes\n",
    "d = int(test[2+c+k])\n",
    "for i in range(d):\n",
    "    x, y = test[3+c+k+i].split(' ')\n",
    "    x, y = int(x), int(y)\n",
    "    game_map[(x,y)] = 'b'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### **Agent** is a class that models our agents with keeping track of their position and id.\n",
    "- **agent_string()**: used in State class to distinguish the differences between states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, x, y, agent_id):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.agent_id = agent_id\n",
    "        self.is_finished = False\n",
    "        \n",
    "    def agent_string(self):\n",
    "        return str(self.x) + str(self.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### **State** is a class that models our observations about the moves of our agents and eating foods or medicines. To solve the problem, we see different sequences of actions by agents that have some consequences like eating or not eating foods or medicines, we model this sequence of actions with this class.\n",
    "- **parent:** uses to keep track of the previous states.\n",
    "- **depth:** shows how far our search goes.\n",
    "- **check_pos():** checks if the current position that the State saw is medicine or food or none of them. If it was medicine, an agent will be added. That medicine will be deleted too. If it was food, only that food will be deleted.\n",
    "- **state_string():** as we saw in Agent class, we have a method used to distinguish the differences between states, so we don't see duplicate states in our search algorithms.\n",
    "- **check_goal():** checks if the current state is our goal state or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    def __init__(self, agents, foods, medicines, parent=None):\n",
    "        self.agents = agents\n",
    "        self.parent = parent\n",
    "        self.medicines = medicines\n",
    "        self.foods = foods\n",
    "        if self.parent == None:\n",
    "            self.depth = 0\n",
    "        else:\n",
    "            self.depth = parent.depth + 1\n",
    "        \n",
    "    def check_pos(self, x, y, agent_id):\n",
    "        if game_map[(x, y)] == 'medicine':\n",
    "            try:\n",
    "                index = self.medicines.index((x,y))\n",
    "            except ValueError:\n",
    "                index = -1\n",
    "            if index != -1:\n",
    "                del self.medicines[index]\n",
    "                new_agent = Agent(n-1, 0, agent_id+1)\n",
    "                self.agents.append(new_agent)\n",
    "        \n",
    "        if game_map[(x, y)] == 'food':\n",
    "            try:\n",
    "                index = self.foods.index((x,y))\n",
    "            except ValueError:\n",
    "                index = -1\n",
    "            if index != -1:\n",
    "                del self.foods[index]\n",
    "            \n",
    "    def state_string(self):\n",
    "        s = ''\n",
    "        for i in self.agents:\n",
    "            s += i.agent_string()\n",
    "        for i in self.foods:\n",
    "            s += str(i)\n",
    "        for i in self.medicines:\n",
    "            s += str(i)\n",
    "        return s\n",
    "    \n",
    "    def check_goal(self):\n",
    "        if len(self.foods) > 0:\n",
    "            return False\n",
    "        for i in self.agents:\n",
    "            if i.x != n-1 or i.y != m-1:\n",
    "                return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Some Useful stuffs\n",
    "- **possible_moves:** possible moves for an agent\n",
    "- **is_valid_pos():** checks if the position is not bigger than the map dimensions and also checks that the position is not blocked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_moves = ['U', 'D', 'R', 'L']\n",
    "\n",
    "def is_valid_pos(x, y):\n",
    "    if x >= n or y >= m or x < 0 or y < 0:\n",
    "        return False\n",
    "    if game_map[(x, y)] == 'b':\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Creating initial agent and initial state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = []\n",
    "start_agent = Agent(0, 0, 1)\n",
    "agents.append(start_agent)\n",
    "start_state = State(agents, foods, medicines)\n",
    "start_state.check_pos(0, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## BFS\n",
    "Breadth-first search (BFS) is an algorithm for searching a tree data structure for a node that satisfies a given property. It starts at the tree root and explores all nodes at the present depth prior to moving on to the nodes at the next depth level. Extra memory, usually a queue, is needed to keep track of the child nodes that were encountered but not yet explored.<br>[See the reference](https://en.wikipedia.org/wiki/Breadth-first_search)<br><br>$ \\bf BFS \\ properties: $\n",
    "- Complete\n",
    "- Optimal: because we move in depth\n",
    "- Time complexity: $\\bf O(b^d)$ where **b** is max branching factor of the search tree and **d** is the depth of the optimal solution.\n",
    "- Space complexity: $ \\bf O(b^d) $<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BFS(start_state):\n",
    "    all_states = 0\n",
    "    fifo = []\n",
    "    fifo.append(start_state)\n",
    "    visited = set()\n",
    "    visited.add(start_state.state_string())\n",
    "\n",
    "    while(True):\n",
    "        if len(fifo) <= 0:\n",
    "            return all_states, state\n",
    "        state = fifo.pop(0)\n",
    "        for i in state.agents:\n",
    "            for move in possible_moves:\n",
    "                if move == 'U':\n",
    "                    new_x, new_y = i.x+1, i.y\n",
    "                if move == 'D':\n",
    "                    new_x, new_y = i.x-1, i.y\n",
    "                if move == 'R':\n",
    "                    new_x, new_y = i.x, i.y+1\n",
    "                if move == 'L':\n",
    "                    new_x, new_y = i.x, i.y-1\n",
    "                if is_valid_pos(new_x, new_y) == True:\n",
    "                    new_agents = copy.deepcopy(state.agents)\n",
    "                    new_agents[i.agent_id - 1].x = new_x\n",
    "                    new_agents[i.agent_id - 1].y = new_y\n",
    "                    new_foods = copy.deepcopy(state.foods)\n",
    "                    new_medicines = copy.deepcopy(state.medicines)\n",
    "                    pre_x, pre_y = state.agents[i.agent_id-1].x, state.agents[i.agent_id-1].y\n",
    "                    new_state = State(new_agents, new_foods, new_medicines, state)\n",
    "                    new_state.check_pos(pre_x, pre_y, i.agent_id)\n",
    "                    all_states += 1\n",
    "                    if new_state.state_string() not in visited:\n",
    "                        if new_state.check_goal() == True:\n",
    "                            return all_states, new_state\n",
    "                        fifo.append(new_state)\n",
    "                        visited.add(new_state.state_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we find all the moves that we can go from a state for all our agents and then check if the new position is valid. If it was a valid position, then we create a new agent and a new state. Finally, we check if we saw the new state before or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Execution time, depth, and number of visited states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The execution time is:  13.241868019104004\n",
      "Goal state is in depth : 11\n",
      "Number of visited states:  279371\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "all_states, last_state = BFS(start_state)\n",
    "end = time.time()\n",
    "print('The execution time is: ', end - start)\n",
    "print('Goal state is in depth :', last_state.depth)\n",
    "print('Number of visited states: ', all_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Printing the path that agents have walked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent:  1  Pos :  (0, 0)\n",
      "Agent:  1  Pos :  (0, 1)\n",
      "Agent:  1  Pos :  (0, 2)\n",
      "Agent:  1  Pos :  (1, 2)\n",
      "Agent:  1  Pos :  (2, 2)\n",
      "Agent:  1  Pos :  (3, 2)\n",
      "Agent:  2  Pos :  (3, 0)\n",
      "Agent:  2  Pos :  (2, 0)\n",
      "Agent:  2  Pos :  (2, 1)\n",
      "Agent:  2  Pos :  (2, 2)\n",
      "Agent:  2  Pos :  (3, 2)\n",
      "Agent:  2  Pos :  (3, 3)\n",
      "Agent:  1  Pos :  (3, 3)\n"
     ]
    }
   ],
   "source": [
    "par = copy.deepcopy(last_state)\n",
    "moves = []\n",
    "while(par != None):\n",
    "    for i in par.agents:\n",
    "        moves.append((i.agent_id, (i.x, i.y)))\n",
    "    par = par.parent  \n",
    "moves = list(dict.fromkeys(moves))\n",
    "\n",
    "for move in moves[::-1]:\n",
    "    print('Agent: ', move[0], ' Pos : ', move[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## BFS Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Test | goal depth | visited states |  time(sec)\n",
    "|------|------------|----------------|------------\n",
    "|  1   |     11     |      4304      |    0.135\n",
    "|  2   |     11     |     279371     |    13.144\n",
    "|  3   |     19     |     504847     |    21.686\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## IDS\n",
    "Iterative deepening search or more specifically iterative deepening depth-first search (IDS or IDDFS) is a state space/graph search strategy in which a depth-limited version of depth-first search is run repeatedly with increasing depth limits until the goal is found. IDDFS is optimal like breadth-first search, but uses much less memory; at each iteration, it visits the nodes in the search tree in the same order as depth-first search, but the cumulative order in which nodes are first visited is effectively breadth-first.<br>[See the reference](https://en.wikipedia.org/wiki/Iterative_deepening_depth-first_search)\n",
    "<br><br>$ \\bf IDS \\ properties: $\n",
    "- Complete\n",
    "- Optimal (if step cost = 1): because we limit depth of DFS.\n",
    "- Time complexity: $\\bf O(b^d)$ where **b** is max branching factor of the search tree and **d** is the depth of the optimal solution.\n",
    "- Space complexity: $ \\bf O(bd) $\n",
    "- We can see that IDS uses much less space compared to BFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IDS(state, depth):\n",
    "    global all_states\n",
    "    visited.add((state.state_string(), state.depth))\n",
    "    if state.check_goal() == True:\n",
    "        print('goal')\n",
    "        return state\n",
    "    if depth <= 0:\n",
    "        return None\n",
    "    for i in state.agents:\n",
    "        for move in possible_moves:\n",
    "            if move == 'U':\n",
    "                new_x, new_y = i.x+1, i.y\n",
    "            if move == 'D':\n",
    "                new_x, new_y = i.x-1, i.y\n",
    "            if move == 'R':\n",
    "                new_x, new_y = i.x, i.y+1\n",
    "            if move == 'L':\n",
    "                new_x, new_y = i.x, i.y-1\n",
    "            if is_valid_pos(new_x, new_y) == True:\n",
    "                new_agents = copy.deepcopy(state.agents)\n",
    "                new_agents[i.agent_id - 1].x = new_x\n",
    "                new_agents[i.agent_id - 1].y = new_y\n",
    "                new_foods = copy.deepcopy(state.foods)\n",
    "                new_medicines = copy.deepcopy(state.medicines)\n",
    "                pre_x, pre_y = state.agents[i.agent_id-1].x, state.agents[i.agent_id-1].y\n",
    "                new_state = State(new_agents, new_foods, new_medicines, state)\n",
    "                new_state.check_pos(pre_x, pre_y, i.agent_id)\n",
    "                all_states += 1\n",
    "                \n",
    "                if (new_state.state_string(), new_state.depth) not in visited:\n",
    "                    res = IDS(new_state, depth-1)\n",
    "                    if res != None:\n",
    "                        return res\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we recursively go through each depth of our tree and search for the goal state. The other things are similar to the BFS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Execution time, depth, and number of visited states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "goal\n",
      "The execution time is:  39.03666925430298\n",
      "Goal state is in depth : 11\n",
      "Number of visited states:  832722\n"
     ]
    }
   ],
   "source": [
    "depth = 0\n",
    "start = time.time()\n",
    "all_states = 0\n",
    "\n",
    "while True:\n",
    "    visited = set()\n",
    "    last_state = IDS(start_state, depth)\n",
    "    if last_state != None:\n",
    "        break\n",
    "    print(depth)\n",
    "    depth += 1\n",
    "end = time.time()\n",
    "print('The execution time is: ', end - start)\n",
    "print('Goal state is in depth :', last_state.depth)\n",
    "print('Number of visited states: ', all_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Printing the path that agents have walked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent:  1  Pos :  (0, 0)\n",
      "Agent:  1  Pos :  (0, 1)\n",
      "Agent:  1  Pos :  (0, 2)\n",
      "Agent:  1  Pos :  (1, 2)\n",
      "Agent:  1  Pos :  (2, 2)\n",
      "Agent:  1  Pos :  (3, 2)\n",
      "Agent:  2  Pos :  (3, 0)\n",
      "Agent:  2  Pos :  (2, 0)\n",
      "Agent:  2  Pos :  (2, 1)\n",
      "Agent:  2  Pos :  (2, 2)\n",
      "Agent:  2  Pos :  (3, 2)\n",
      "Agent:  2  Pos :  (3, 3)\n",
      "Agent:  1  Pos :  (3, 3)\n"
     ]
    }
   ],
   "source": [
    "par = copy.deepcopy(last_state)\n",
    "moves = []\n",
    "while(par != None):\n",
    "    for i in par.agents:\n",
    "        moves.append((i.agent_id, (i.x, i.y)))\n",
    "    par = par.parent  \n",
    "moves = list(dict.fromkeys(moves))\n",
    "\n",
    "for move in moves[::-1]:\n",
    "    print('Agent: ', move[0], ' Pos : ', move[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## IDS Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Test | goal depth | visited states |  time(sec)\n",
    "|------|------------|----------------|------------\n",
    "|  1   |     11     |     24731      |    0.7487\n",
    "|  2   |     11     |     832722     |    37.180\n",
    "|  3   |     19     |     2222311    |    91.587"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### What is Heuristic function?\n",
    "The **heuristic function** is a way to inform the search about the direction to a goal. It uses an evaluation function to rank states and select the most promising one for expansion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### The heuristic function I used\n",
    "I calculated the distance of all agents to the endpoint(n-1, m-1), then I picked the largest one as my **estimated cost from a state to the goal state** or **heuristic function** $\\bf h(n)$.<br>\n",
    "This heuristic is similar to the **'Manhattan distance'**. (Manhattan distance is calculated as the sum of the absolute differences between the two vectors.)<br>Then I added the depth of the current state as my **cost to reach the current state** or $\\bf g(n)$.<br>\n",
    "So the evaluation function I used is: $ \\bf f(n) = g(n) + h(n) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is this heuristic function consistent?\n",
    "A heuristic $\\bf h$ is **consistent** (or monotone) if\n",
    "- for each node N and each child N’ of N: $h(N) ≤ c(N,N’) + h(N’)$ <br>$c(N,N’)$ is the true cost to go from N to N'.\n",
    "- for each goal node G: $h(G) = 0$<br>\n",
    "\n",
    "If these conditions are confirmed, we can say that the $\\bf f$ value along a path never decreases and the A-star search is optimal.<br><br>\n",
    "#### prove:\n",
    "Because if our agents move(wherever it goes), then $\\bf h(current) - \\bf h(goal) <= 1$, so this heuristic is consistent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_function(state, weight=1):\n",
    "    min_dist = -1\n",
    "    \n",
    "    for agent in state.agents:\n",
    "        if min_dist < abs(agent.x - n) + abs(agent.y - m):\n",
    "            min_dist = abs(agent.x - n) + abs(agent.y - m)\n",
    "        \n",
    "    return min_dist * weight + state.depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Priority queue\n",
    "We used priority queue in A-star algorithm, because we need to pop the state that has minimum evaluation function every time. So with this priority queue, we can pop states in O(1). <br>This Node class, helps us to have a priority queue of list of tuples.<br>[See the reference code](https://stackoverflow.com/a/59956131/12576240)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self, state, val):\n",
    "        self.state = state\n",
    "        self.val = val\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.val <= other.val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## $\\bf A^*$\n",
    "A* is a graph traversal and path search algorithm, which is often used in many fields of computer science due to its completeness, optimality, and optimal efficiency.<br><br>$ \\bf A^* \\ properties: $\n",
    "- Complete\n",
    "- Optimal: if we have a consistent heuristic.\n",
    "- Time complexity: number of nodes for which $\\bf f(n) <= C^*$ (exponential)\n",
    "- Space complexity: exponential\n",
    "\n",
    "<br>In $A^*$, we use **evaluation function** to have some information about where our agents should go. At each iteration of its main loop, $A^*$ needs to determine which of its paths to extend. It does so based on the cost of the path and an estimate of the cost required to extend the path all the way to the goal.<br>\n",
    "In **weighted** $\\bf A^*$ **search**, we take an admissible heuristic, multiply it by an α > 1, and then we perform $ A^*$ search as usual. Fewer nodes tend to get expanded, but the resulting solution may be suboptimal (its cost will be at most α times the cost of the optimal solution)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Astar(start_state, weight=1):\n",
    "    all_states = 0\n",
    "    min_heap = []\n",
    "    heapq.heappush(min_heap, Node(start_state, evaluation_function(start_state, weight)))\n",
    "    \n",
    "    visited = set()\n",
    "    visited.add(start_state.state_string())\n",
    "    \n",
    "    while(True):\n",
    "        if len(min_heap) <= 0:\n",
    "            return state\n",
    "        state = heapq.heappop(min_heap).state\n",
    "\n",
    "        for i in state.agents:\n",
    "            for move in possible_moves:\n",
    "                if move == 'U':\n",
    "                    new_x, new_y = i.x+1, i.y\n",
    "                if move == 'D':\n",
    "                    new_x, new_y = i.x-1, i.y\n",
    "                if move == 'R':\n",
    "                    new_x, new_y = i.x, i.y+1\n",
    "                if move == 'L':\n",
    "                    new_x, new_y = i.x, i.y-1\n",
    "\n",
    "                if is_valid_pos(new_x, new_y) == True:\n",
    "                    new_agents = copy.deepcopy(state.agents)\n",
    "                    new_agents[i.agent_id - 1].x = new_x\n",
    "                    new_agents[i.agent_id - 1].y = new_y\n",
    "                    new_foods = copy.deepcopy(state.foods)\n",
    "                    new_medicines = copy.deepcopy(state.medicines)\n",
    "                    pre_x, pre_y = state.agents[i.agent_id-1].x, state.agents[i.agent_id-1].y\n",
    "                    new_state = State(new_agents, new_foods, new_medicines, state)\n",
    "                    new_state.check_pos(pre_x, pre_y, i.agent_id)\n",
    "                    all_states += 1\n",
    "                    if new_state.state_string() not in visited:\n",
    "                        if new_state.check_goal() == True:\n",
    "                            return all_states, new_state\n",
    "                        heapq.heappush(min_heap, Node(new_state, evaluation_function(new_state, weight)))\n",
    "                        visited.add(new_state.state_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Execution time, depth, and number of visited states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "all_states, last_state = Astar(start_state, weight=1)\n",
    "end = time.time()\n",
    "print('The execution time is: ', end - start)\n",
    "print('Goal state is in depth :', last_state.depth)\n",
    "print('Number of visited states: ', all_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Printing the path that agents have walked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par = copy.deepcopy(last_state)\n",
    "moves = []\n",
    "while(par != None):\n",
    "    for i in par.agents:\n",
    "        moves.append((i.agent_id, (i.x, i.y)))\n",
    "    par = par.parent  \n",
    "moves = list(dict.fromkeys(moves))\n",
    "\n",
    "for move in moves[::-1]:\n",
    "    print('Agent: ', move[0], ' Pos : ', move[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## A* and weighted A* results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Test |   weight  | goal depth | visited states |  time(sec)\n",
    "|------|-----------|------------|----------------|------------\n",
    "|  1   |     1     |     11     |      2201      |    0.08025\n",
    "|  1   |     1.5   |     11     |      1093      |    0.04404\n",
    "|  1   |     2     |     11     |      403       |    0.02029\n",
    "|  2   |     1     |     11     |      15507     |    0.80652\n",
    "|  2   |     1.5   |     11     |      3374      |    0.17202\n",
    "|  2   |     2     |     11     |      1976      |    0.10705\n",
    "|  3   |     1     |     19     |      54540     |    2.58487\n",
    "|  3   |     1.5   |     19     |      19966     |    0.97051\n",
    "|  3   |     2     |     19     |      4804      |    0.22370\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Final results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 1:\n",
    "|                                      | goal depth | visited states  |  mean time(sec)\n",
    "|--------------------------------------|------------|-----------------|--------------------\n",
    "|  **BFS**                             |     11     |      4304       |    0.1312236785888\n",
    "|  **IDS**                             |     11     |      24731      |    0.7816061178843\n",
    "|$\\bf A^*$                             |     11     |      2201       |    0.0751590003967\n",
    "|**weighted**$$\\bf A^* (\\alpha=1.5) $$ |     11     |      1093       |    0.0366712280273\n",
    "|**weighted**$$\\bf A^* (\\alpha=2  ) $$ |     11     |      403        |    0.0140038562774\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 2:\n",
    "|                                      | goal depth | visited states |  mean time(sec)\n",
    "|--------------------------------------|------------|----------------|------------\n",
    "|  **BFS**                             |     11     |      279371    |    13.074145078659\n",
    "|  **IDS**                             |     11     |      832722    |    38.386329889297\n",
    "|$\\bf A^*$                             |     11     |      15507     |    0.8199410343170\n",
    "|**weighted**$$\\bf A^* (\\alpha=1.5) $$ |     11     |      3374      |    0.1913731098175\n",
    "|**weighted**$$\\bf A^* (\\alpha=2  ) $$ |     11     |      1976      |    0.1048440933224\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 3:\n",
    "|                                      | goal depth | visited states |  mean time(sec)\n",
    "|--------------------------------------|------------|----------------|------------\n",
    "|  **BFS**                             |     19     |      50484     |    22.16307020187378\n",
    "|  **IDS**                             |     19     |      2222311   |    93.60527706146243\n",
    "|$\\bf A^*$                             |     19     |      54540     |    2.51611685752868\n",
    "|**weighted**$$\\bf A^* (\\alpha=1.5) $$ |     19     |      19966     |    0.90068387985229\n",
    "|**weighted**$$\\bf A^* (\\alpha=2  ) $$ |     19     |      4804      |    0.21028232574462\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Conclusion\n",
    "#### Alogorithms Properties:\n",
    "If we compare these 3 algorithms based on their properties, we can say all of these algorithms are **optimal** and **complete**.<br>\n",
    "BFS and IDS have the same **time complexity** but IDS uses much less space compared to BFS.<br>And the time complexity in $A^*$ is the number of nodes which heuristic expands.\n",
    "#### Time Results:\n",
    "Using **informed search** strategies can help us to reach the goal state in efficient time compared to **Uninformed search** strategies, because with using informed search, we give our agents some other informations about the world that can help them to make better decisions.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
